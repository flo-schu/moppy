[case-study]
logging = DEBUG
observations = simulated_noisy_data.nc

[simulation]
input_files = config.json 
dimensions = time
data_variables = rabbits wolves
replicated = 0
data_variables_max = nan nan
data_variables_min = 0 0
evaluator_dim_order = time

[model-parameters]
alpha = value=0.5 min=0.1 max=5.0 prior=lognorm(s=0.1,scale=0.50) free=True
beta = value=0.02 min=0.005 max=0.2 prior=lognorm(s=0.1,scale=0.02) free=True
# sigma_rabbits.prior = halfnorm(scale=0.1)

[error-model]
wolves = lognorm(scale=wolves+EPS,s=0.1)
rabbits = lognorm(scale=rabbits+EPS,s=0.1)

[inference]
backend = pymoo
objective_function = total_average
n_objectives = 1
EPS = 1e-8

[multiprocessing]
cores = 1

[inference.pyabc]
population_size = 100
minimum_epsilon = 0.01
min_eps_diff = 0.001
max_nr_populations = 50
sampler = SingleCoreSampler
database_path = pyabc_database.db


[inference.pyabc.redis]
port = 1803
password = simulate
eval.model_id = 0
eval.history_id = -1
eval.n_predictions = 50

[inference.pymoo]
population_size = 200
max_nr_populations = 10
algorithm = UNSGA3
ftol = 0.01
xtol = 0.001
verbose = True


[inference.numpyro]
gaussian_base_distribution = 0
chains = 1
draws = 1000
warmup = 500
init_strategy = init_to_median
kernel = nuts
sa_adapt_state_size = 10
thinning = 1