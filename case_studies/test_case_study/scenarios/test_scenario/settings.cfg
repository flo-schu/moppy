[case-study]
logging = DEBUG
observations = simulated_noisy_data.nc

[simulation]
input_files = config.json 
dimensions = time
data_variables = rabbits wolves
replicated = 0
data_variables_max = nan nan
data_variables_min = 0 0
evaluator_dim_order = time

[free-model-parameters]
alpha.value = 0.5
alpha.min = 0 
alpha.max = 1
alpha.prior = lognorm(s=0.1,scale=0.5)
beta.value = 0.02
beta.prior = lognorm(s=0.1,scale=0.02)
# sigma_rabbits.prior = halfnorm(scale=0.1)

[error-model]
wolves = lognorm(scale=wolves+EPS,s=0.1)
rabbits = lognorm(scale=rabbits+EPS,s=0.1)

[inference]
backend = pymoo
objective_function = total_average
n_objectives = 1
EPS = 1e-8

[multiprocessing]
cores = 1

[inference.pyabc]
population_size = 100
minimum_epsilon = 0.01
min_eps_diff = 0.001
max_nr_populations = 50
sampler = SingleCoreSampler
database_path = pyabc_database.db


[inference.pyabc.redis]
port = 1803
password = simulate
eval.model_id = 0
eval.history_id = -1
eval.n_predictions = 50

[inference.pymoo]
population_size = 50
max_nr_populations = 20
algorithm = UNSGA3
ftol = 0.01
xtol = 0.001
verbose = True


[inference.numpyro]
gaussian_base_distribution = 0
chains = 1
draws = 1000
warmup = 500
init_strategy = init_to_median
kernel = nuts
sa_adapt_state_size = 10
thinning = 1